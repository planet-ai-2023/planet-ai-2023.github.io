---
layout: post
title:  "Stable Diffusion and SDXL"
date: 2023-08-08
image: assets/images/12_alan_bean.png
tags: [ AI, resources ]
---



**ARTICLES**   

- Dustin Podell, Zion English, Kyle Lacey, Andreas Blattmann, Tim Dockhorn, Jonas Müller, Joe Penna, and Robin Rombach. SDXL: Improving Latent Diffusion Models for High-Resolution Image Synthesis. In <em>CVPR</em>, 2023. [pdf](https://arxiv.org/pdf/2307.01952.pdf){:target="_blank"} / [code](https://github.com/Stability-AI/generative-models){:target="_blank"} / [Model weights](https://huggingface.co/stabilityai/){:target="_blank"}
- Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Björn Ommer. High-resolution
image synthesis with latent diffusion models. In <em>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em>, pages 10684–10695, June 2022. [pdf](https://arxiv.org/pdf/2112.10752.pdf){:target="_blank"} / [project page](https://ommer-lab.com/research/latent-diffusion-models/){:target="_blank"}   
- Yang Song and Stefano Ermon. Generative Modeling by Estimating Gradients of the Data Distribution.  In <em>NeurIPS</em>, 2019. [pdf](https://arxiv.org/pdf/1907.05600.pdf){:target="_blank"}
- Yang Song and Stefano Ermon. Improved Techniques for Training Score-Based Generative Models. In <em>NeurIPS</em>, 2020. [pdf](https://arxiv.org/pdf/2006.09011.pdf){:target="_blank"}
- Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising Diffusion Probabilistic Models. <em>arxiv Preprint arxiv:2006.11239</em>, 2020. [pdf](https://arxiv.org/pdf/2006.11239.pdf){:target="_blank"}
- Olaf Ronneberger, Philipp Fischer, and Thomas Brox. U-Net: Convolutional Networks for Biomedical
Image Segmentation. In <em>MICCAI (3), volume 9351 of Lecture Notes in Computer Science</em>, pages 234–241. Springer, 2015. [pdf](https://arxiv.org/pdf/1505.04597.pdf){:target="_blank"}
- Kevin Frans,Lisa B.Soros, and Olaf Witkowski. Clipdraw. Exploring text-to-drawing synthesis through language- image encoders. In <em>ArXiv</em>, abs/2106.14843, 2021. [pdf](https://arxiv.org/pdf/2106.14843.pdf){:target="_blank"}
- Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, and Ilya Sutskever. Learning Transferable Visual Models From Natural Language Supervision. In <em>CVPR</em>, 2021. [pdf](https://arxiv.org/pdf/2103.00020.pdf){:target="_blank"}
- Jonathan Ho, and Tim Salimans. Classifier-Free Diffusion Guidance. In <em>NeurIPS</em>, 2022. [pdf](https://arxiv.org/pdf/2207.12598.pdf){:target="_blank"}
- Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, and Neil Houlsby. An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale. In <em>ICLR</em>, 2021. [pdf](https://arxiv.org/pdf/2010.11929.pdf){:target="_blank"}
- Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. Attention is all you need. In <em>NIPS</em>, pages 5998–6008, 2017. [pdf](https://arxiv.org/pdf/1706.03762.pdf){:target="_blank"}

- Lvmin Zhang and Maneesh Agrawala. Adding Conditional Control to Text-to-Image Diffusion Models. In <em>CVPR</em>, 2023. [pdf](https://arxiv.org/pdf/2302.05543.pdf){:target="_blank"}
- Shanchuan Lin, Bingchen Liu, Jiashi Li, and Xiao Yang. Common Diffusion Noise Schedules and Sample Steps are Flawed. In <em>CVPR</em>, 2023. [pdf](https://arxiv.org/pdf/2305.08891.pdf){:target="_blank"}
- Tim Brooks, Aleksander Holynski, and Alexei A. Efros. InstructPix2Pix: Learning to Follow Image Editing Instructions. In <em>CVPR</em>, 2023. [pdf](https://arxiv.org/pdf/2211.09800.pdf){:target="_blank"}
- Ben Poole, Ajay Jain, Jonathan T. Barron, and Ben Mildenhall. DreamFusion: Text-to-3D using 2D Diffusion. In <em>CVPR</em>, 2022. [pdf](https://arxiv.org/pdf/2209.14988.pdf){:target="_blank"}
- Jonathan Tseng, Castellon Rodrigo, and C. Karen Liu. Edge: Editable dance generation from music. In <em>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, pp. 448-458, 2023. [pdf](https://arxiv.org/pdf/2211.10658.pdf){:target="_blank"}
- Roman Suvorov, Elizaveta Logacheva, Anton Mashikhin, Anastasia Remizova, Arsenii Ashukha, Aleksei Silvestrov, Naejin Kong, Harshith Goka, Kiwoong Park, and Victor Lempitsky. Resolution-robust Large Mask Inpainting with Fourier Convolutions. In <em>CVPR</em>, 2022. [pdf](https://arxiv.org/pdf/2109.07161.pdf){:target="_blank"} / [project page](https://advimman.github.io/lama-project/){:target="_blank"}
- Nataniel Ruiz, Yuanzhen Li, Varun Jampani, Yael Pritch, Michael Rubinstein, and Kfir Aberman. Dreambooth: Fine tuning text-to-image diffusion models for subject-driven generation. In <em>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, pp. 22500-22510. 2023. [pdf](https://arxiv.org/pdf/2208.12242.pdf){:target="_blank"} / [project page](https://dreambooth.github.io/){:target="_blank"}
- Rinon Gal, Yuval Alaluf, Yuval Atzmon, Or Patashnik, Amit H. Bermano, Gal Chechik, and Daniel Cohen-Or. An Image is Worth One Word: Personalizing Text-to-Image Generation using Textual Inversion. In <em>CVPR</em>, 2022. [pdf](https://arxiv.org/pdf/2208.01618.pdf){:target="_blank"}


**The Thumb Image**   
The thumb image is published in 2008 by NASA. Astronaut Alan L. Bean, lunar module pilot, deploys components of the Apollo Lunar Surface Experiments Package during the first Apollo 12 spacewalk on the moon. The photo was taken by astronaut Charles "Pete" Conrad Jr., commander. 




